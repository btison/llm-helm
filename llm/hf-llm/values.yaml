replicaCount: 1

image:
  repository: ghcr.io/huggingface/text-generation-inference
  pullPolicy: IfNotPresent
  tag: 1.3

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations: {}

podSecurityContext: 
  runAsNonRoot: true
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL

livenessProbe:
  httpGet:
    path: /health
    port: http
    scheme: HTTP
  timeoutSeconds: 8
  periodSeconds: 100
  successThreshold: 1
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /health
    port: http
    scheme: HTTP
  timeoutSeconds: 5
  periodSeconds: 30
  successThreshold: 1
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /health
    port: http
    scheme: HTTP
  timeoutSeconds: 1
  periodSeconds: 30
  successThreshold: 1
  failureThreshold: 24
  initialDelaySeconds: 60

resources:
  limits:
    cpu: '8'
    memory: 24Gi
    nvidia.com/gpu: '1'
  requests:
    cpu: '6'

service:
  type: ClusterIP
  port: 3000
  containerPort: 3000
  portName: http

route:
  enabled: true
  host:
  tlsEnabled: true
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

llm:
  modelId: mistralai/Mistral-7B-Instruct-v0.2
  maxInputLength: 4096
  maxTotalTokens: 8192
  modelCache: /models-cache

argocd:
  enabled: true

odf:
  argocd:
    syncwave: "-1"

pvc:
  argocd:
    syncwave: "-1"
  capacity: 50Gi
  storageClassName: ocs-storagecluster-cephfs
  volumeMode: Filesystem
